{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Configure le service EdgeDriver\n",
    "service = Service(executable_path=r\"C:\\Users\\Electro Fatal\\Desktop\\file\\edgedriver_win64\\msedgedriver.exe\")\n",
    "\n",
    "# Lance une instance de Microsoft Edge\n",
    "driver = webdriver.Edge(service=service)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.webofscience.com.eressources.imist.ma/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_field = driver.find_element(By.ID, \"email\")\n",
    "password_field = driver.find_element(By.ID, \"password\")\n",
    "\n",
    "email_field.send_keys('youness.elmeki@usms.ac.ma')\n",
    "password_field.send_keys('Youness@@2002')\n",
    "\n",
    "password_field.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_information(id):\n",
    "    # Charge la page de l'auteur et vérifie si elle est prête\n",
    "    if wait_for_page_to_load(id):\n",
    "        infos = {}\n",
    "        infos['ID de l\\'Auteur'] = id\n",
    "        for key, item in author_information.items():\n",
    "            # Si la clé est \"Co-auteurs\", extrait les noms des co-auteurs\n",
    "            if key == 'Co-auteurs':\n",
    "                co_auteurs = driver.find_elements(By.CLASS_NAME, 'authors-list-link')\n",
    "                list_co_auteurs = [auteur.text for auteur in co_auteurs]\n",
    "                infos['co_auteurs'] = list_co_auteurs\n",
    "            # Si l'item est un dictionnaire, récupère des métriques spécifiques\n",
    "            elif isinstance(item, dict):\n",
    "                metric_descriptor = driver.find_elements(By.CLASS_NAME, key)\n",
    "                for metric in metric_descriptor:\n",
    "                    if metric.text in item.values():\n",
    "                        value = metric.find_element(By.XPATH, './preceding-sibling::div').text\n",
    "                        infos[metric.text] = value\n",
    "            # Récupère les autres informations\n",
    "            else:\n",
    "                value = driver.find_element(By.CLASS_NAME, f'{item}').text\n",
    "                infos[key] = value\n",
    "    return infos\n",
    "\n",
    "def extract_article_details(driver, article_link):\n",
    "    # Ouvre le lien de l'article\n",
    "    driver.get(article_link)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, 'title'))\n",
    "    )\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extrait l'ISSN de l'article\n",
    "    try:\n",
    "        match = re.search(r\"KeyISSN=\\d{4}-\\d{3}[\\dxX]\", str(soup.find_all(\"a\")))\n",
    "        issn = match.group().split('=')[1]\n",
    "    except:\n",
    "        print('ISSN error')\n",
    "\n",
    "    infos = {}\n",
    "    try:\n",
    "        issn\n",
    "        for info in infos_article:\n",
    "            try:\n",
    "                # Récupère le nombre de citations\n",
    "                if info == 'citation-count':\n",
    "                    infoElem = driver.find_element(By.CLASS_NAME, info).text.split('\\n')\n",
    "                    infos[info] = 0 if infoElem[1] == 'Cited References' else infoElem[0]\n",
    "                # Récupère le titre, les mots-clés, ...\n",
    "                elif info in ['title', 'keywordsPlusLink', 'summary-source-title-link']:\n",
    "                    if info == 'keywordsPlusLink':\n",
    "                        infos[info] = ' , '.join([key.text for key in driver.find_elements(By.CLASS_NAME, 'keywordsPlusLink')])\n",
    "                    else:\n",
    "                        infos[info] = driver.find_element(By.CLASS_NAME, info).text\n",
    "                elif info == 'SumAuthTa-DisplayName-author-en-':\n",
    "                    infos[info] = ' ; '.join([element.text for element in driver.find_elements(By.XPATH, \"//a[starts-with(@id,'SumAuthTa-DisplayName-author-en-')]\")])\n",
    "                else:\n",
    "                    infos[info] = driver.find_element(By.ID, info).text\n",
    "            except:\n",
    "                print(info, 'not exist')\n",
    "    except:\n",
    "        print(\"Variable 'issn' does not exist.\")\n",
    "    return infos\n",
    "\n",
    "def search_journal_by_issn(issn):\n",
    "    # Recherche la revue par ISSN sur Scimago\n",
    "    driver.get('https://www.scimagojr.com/')\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, 'searchinput'))\n",
    "    )\n",
    "    try:\n",
    "        # Remplit et soumet le champ de recherche avec l'ISSN\n",
    "        search_box = driver.find_element(By.ID, \"searchinput\")\n",
    "        search_box.send_keys(issn)\n",
    "        search_box.submit()\n",
    "\n",
    "        # Accède au premier résultat de la recherche\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='search_results']/a[@href]\")))\n",
    "        journal_link = driver.find_element(By.XPATH, \"//div[@class='search_results']/a[@href]\")\n",
    "        journal_link.click()\n",
    "\n",
    "        # Récupère les informations de la revue\n",
    "        journal_info = {}\n",
    "        journal_info['Nom'] = driver.find_element(By.XPATH, \"//h1\").text\n",
    "\n",
    "        # Récupère l'éditeur, l'ISSN, l'indexation, H-index, quartile, SJR, impact factor, et portée thématique\n",
    "        try:\n",
    "            journal_info['Editeur'] = driver.find_element(By.XPATH, \"//div[h2[text()='Publisher']]/p/a\").text\n",
    "        except NoSuchElementException:\n",
    "            journal_info['Editeur'] = 'Non disponible'\n",
    "        try:\n",
    "            issn_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[h2[text()='ISSN']]/p\"))\n",
    "            )\n",
    "            journal_info['ISSN'] = issn_element.text\n",
    "        except NoSuchElementException:\n",
    "            journal_info['ISNN'] = 'Non disponible'\n",
    "        try:\n",
    "            journal_info['Index'] = driver.find_element(By.XPATH, \"//div[h2[text()='Coverage']]/p\").text\n",
    "        except NoSuchElementException:\n",
    "            journal_info['Index'] = 'Non disponible'\n",
    "        try:\n",
    "            journal_info['H-index'] = driver.find_element(By.XPATH, \"//div[h2[text()='H-Index']]/p\").text\n",
    "        except NoSuchElementException:\n",
    "            journal_info['H-index'] = 'Non disponible'\n",
    "        try:\n",
    "            journal_info['Quartile'] = driver.find_element(By.XPATH, \"(//div[@class='cellcontent']//table/tbody/tr[last()]/td[3])[1]\").text\n",
    "        except NoSuchElementException:\n",
    "            journal_info['Quartile'] = 'Non disponible'\n",
    "        try:\n",
    "            journal_info['SJR'] = driver.find_element(By.XPATH, \"(//div[@class='cellcontent']//table/tbody/tr[last()]/td[3])[2]\").text\n",
    "        except NoSuchElementException:\n",
    "            journal_info['SJR'] = 'Non disponible'\n",
    "        try:\n",
    "            journal_info['Impact factor'] = driver.find_element(By.XPATH, \"(//div[@class='cellcontent']//table/tbody/tr[last()]/td[3])[4]\").text\n",
    "        except NoSuchElementException:\n",
    "            journal_info['Impact factor'] = 'Non disponible'\n",
    "        try:\n",
    "            journal_info['Portee thematique'] = driver.find_element(By.CLASS_NAME, 'fullwidth').text.split('\\n', 1)[-1].strip()\n",
    "        except NoSuchElementException:\n",
    "            journal_info['Portee thematique'] = 'Non disponible'\n",
    "\n",
    "        return journal_info\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(f\"Revue avec ISSN {issn} non trouvée.\")\n",
    "        return None\n",
    "\n",
    "def wait_for_page_to_load(user_id):\n",
    "    # Charge la page de l'auteur et vérifie qu'elle est prête\n",
    "    driver.get(f\"https://www.webofscience.com.eressources.imist.ma/wos/author/record/{user_id}\")\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'onetrust-close-btn-handler'))\n",
    "        )\n",
    "        btn_cookies(driver)\n",
    "        scroll_slowly(driver, scroll_pause_time=0.2, scroll_increment=100)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'attente du chargement de la page : {e}\")\n",
    "        return False\n",
    "\n",
    "def btn_cookies(driver):\n",
    "\n",
    "    try:\n",
    "        cookies_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'onetrust-close-btn-handler'))\n",
    "        )\n",
    "        if cookies_button.is_displayed():\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, 'onetrust-close-btn-handler'))\n",
    "            ).click()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la gestion des cookies : {e}\")\n",
    "\n",
    "def get_article_titles():\n",
    "    titles = []\n",
    "\n",
    "    while True:\n",
    "        # Récupère les liens des articles présents sur la page\n",
    "        articles = driver.find_elements(By.CSS_SELECTOR, '.title')\n",
    "        for article in articles:\n",
    "            titles.append(article.get_attribute('href'))\n",
    "\n",
    "        # Passe à la page suivante si elle existe\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, '//button[@data-ta=\"next-page-button\"]')\n",
    "            if 'mat-button-disabled' in next_button.get_attribute('class'):\n",
    "                break\n",
    "            else:\n",
    "                next_button.click()\n",
    "                scroll_slowly(driver, scroll_pause_time=0.2, scroll_increment=100)\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "\n",
    "    return titles\n",
    "\n",
    "def scroll_slowly(driver, scroll_pause_time=0.1, scroll_increment=100):\n",
    "    # Scrolle lentement\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    current_scroll_position = 0\n",
    "\n",
    "    while current_scroll_position < last_height:\n",
    "        current_scroll_position += scroll_increment\n",
    "        driver.execute_script(f\"window.scrollTo(0, {current_scroll_position});\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#informations auteurs /articles\n",
    "author_information = {\n",
    "    'nom_complet' : 'wat-author-name',\n",
    "    'pays_affiliation' : 'more-details',\n",
    "    'Co-auteurs' : 'authors-list-link',\n",
    "    'wat-author-metric-descriptor' : {\n",
    "        'H-index' : 'H-Index',\n",
    "        'Citations_totales' : 'Sum of Times Cited'\n",
    "        }\n",
    "}\n",
    "infos_article = ['title','SumAuthTa-DisplayName-author-en-','FullRTa-pubdate' , 'summary-source-title-link' ,'keywordsPlusLink', 'citation-count','FullRTa-DOI','FullRTa-abstract-basic','FullRTa-doctype-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID de l'auteur\n",
    "author_data = get_author_information(1410815)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'auteurs.csv'\n",
    "\n",
    "# CSV file\n",
    "with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the headers\n",
    "    writer.writerow(author_data.keys())\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerow([author_data[\"ID de l'Auteur\"],\n",
    "                     author_data[\"nom_complet\"],\n",
    "                     author_data[\"pays_affiliation\"],\n",
    "                     ', '.join(author_data[\"co_auteurs\"]),\n",
    "                     author_data[\"H-Index\"],\n",
    "                     author_data[\"Sum of Times Cited\"]])\n",
    "\n",
    "articles = get_article_titles()\n",
    "\n",
    "print(f\"Data saved successfully to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "all_articles_data = []  # Liste pour stocker data de tous les articles\n",
    "\n",
    "for article_link in articles:\n",
    "    try:\n",
    "        article_infos = extract_article_details(driver, article_link)\n",
    "        all_articles_data.append(article_infos)\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout occurred while loading {article_link}. Skipping to the next article.\")\n",
    "\n",
    "data_to_save = {\n",
    "    \"Auteur\": author_data,\n",
    "    \"Articles publiés\": all_articles_data\n",
    "}\n",
    "\n",
    "# Enregistrer data dans un fichier JSON\n",
    "with open(\"author_articles_data.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data_to_save, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Les informations ont été enregistrées dans 'author_articles_data.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "issn = \"1077-3118\"\n",
    "journal_data = search_journal_by_issn(issn)\n",
    "\n",
    "if journal_data:\n",
    "    print(\"Informations sur la revue:\")\n",
    "    for key, value in journal_data.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Aucune information trouvée pour cet ISSN.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
